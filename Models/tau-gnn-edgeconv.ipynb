{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install --upgrade torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n","!python -c \"import torch; print(torch.__version__); print(torch.version.cuda);\"\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu113.html"]},{"cell_type":"markdown","metadata":{},"source":["## Step1: Dataset Preprocessing"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:20.798531Z","iopub.status.busy":"2022-09-22T09:12:20.798107Z","iopub.status.idle":"2022-09-22T09:12:23.197449Z","shell.execute_reply":"2022-09-22T09:12:23.196298Z","shell.execute_reply.started":"2022-09-22T09:12:20.798442Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import gc\n","import torch\n","import pyarrow as pa\n","from tqdm import tqdm\n","from pyarrow.parquet import ParquetFile\n","from sklearn.neighbors import kneighbors_graph\n","from sklearn.model_selection import train_test_split\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:23.201002Z","iopub.status.busy":"2022-09-22T09:12:23.200016Z","iopub.status.idle":"2022-09-22T09:12:39.254553Z","shell.execute_reply":"2022-09-22T09:12:39.253527Z","shell.execute_reply.started":"2022-09-22T09:12:23.200959Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3200, 125000) torch.Size([3200, 1])\n"]}],"source":["pf = ParquetFile('../input/tau-test-1/BoostedTop_x1_fixed_0.snappy.parquet') \n","rows = next(pf.iter_batches(batch_size = 3200)) \n","df = pa.Table.from_batches([rows]).to_pandas() \n","X_jets = np.array(df['X_jets'].tolist()).astype(np.float32)\n","labels = torch.from_numpy(df['y'].to_numpy()).reshape(-1,1).type(torch.LongTensor)\n","del df, rows\n","print(X_jets.shape, labels.shape)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:39.256254Z","iopub.status.busy":"2022-09-22T09:12:39.255885Z","iopub.status.idle":"2022-09-22T09:12:41.898174Z","shell.execute_reply":"2022-09-22T09:12:41.897171Z","shell.execute_reply.started":"2022-09-22T09:12:39.256225Z"},"trusted":true},"outputs":[],"source":["X_data = X_jets.reshape((-1,125*125,8))\n","\n","# uncommet this line below if choose to use full channels\n","X_data = X_data[:,:,:5]\n","non_black_pixels_mask = np.any(X_data != 0., axis=-1)\n","\n","node_list = []\n","for i, x in enumerate(X_data):\n","    node_list.append(x[non_black_pixels_mask[i]])\n","del X_jets"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:41.901027Z","iopub.status.busy":"2022-09-22T09:12:41.900599Z","iopub.status.idle":"2022-09-22T09:12:42.142476Z","shell.execute_reply":"2022-09-22T09:12:42.141479Z","shell.execute_reply.started":"2022-09-22T09:12:41.900946Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3200/3200 [00:00<00:00, 13913.65it/s]\n"]}],"source":["dataset = []\n","for i,nodes in enumerate(tqdm(node_list)):\n","    dataset.append(Data(x=torch.from_numpy(nodes), y=labels[i]))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:42.144451Z","iopub.status.busy":"2022-09-22T09:12:42.144070Z","iopub.status.idle":"2022-09-22T09:12:42.314588Z","shell.execute_reply":"2022-09-22T09:12:42.313527Z","shell.execute_reply.started":"2022-09-22T09:12:42.144414Z"},"trusted":true},"outputs":[{"data":{"text/plain":["23"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["del labels, node_list\n","gc.collect()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:42.328717Z","iopub.status.busy":"2022-09-22T09:12:42.328354Z","iopub.status.idle":"2022-09-22T09:12:42.340397Z","shell.execute_reply":"2022-09-22T09:12:42.338832Z","shell.execute_reply.started":"2022-09-22T09:12:42.328682Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2592 288 288\n"]}],"source":["rand_seed = 42\n","X_train, X_test = train_test_split(dataset, test_size=0.1, random_state = rand_seed)\n","X_train, X_val = train_test_split(X_train, test_size=0.1, random_state = rand_seed)\n","print(len(X_train), len(X_val), len(X_val))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:42.367556Z","iopub.status.busy":"2022-09-22T09:12:42.367285Z","iopub.status.idle":"2022-09-22T09:12:42.380304Z","shell.execute_reply":"2022-09-22T09:12:42.378878Z","shell.execute_reply.started":"2022-09-22T09:12:42.367530Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch: DataBatch(x=[36159, 5], y=[32], batch=[36159], ptr=[33])\n","Labels: tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])\n","Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"]}],"source":["train_loader = DataLoader(X_train, batch_size=32, shuffle=True)\n","val_loader = DataLoader(X_val, batch_size=32, shuffle=True)\n","test_loader = DataLoader(X_test, batch_size=32, shuffle=False)\n","batch = next(iter(test_loader))\n","print(\"Batch:\", batch)\n","print(\"Labels:\", batch.y[:10])\n","print(\"Batch indices:\", batch.batch[:40])"]},{"cell_type":"markdown","metadata":{},"source":["# Step2: Define Dynamic Edge Convolution GNN Model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:42.382444Z","iopub.status.busy":"2022-09-22T09:12:42.381807Z","iopub.status.idle":"2022-09-22T09:12:42.388689Z","shell.execute_reply":"2022-09-22T09:12:42.387744Z","shell.execute_reply.started":"2022-09-22T09:12:42.382406Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torch.optim as optim\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:42.390854Z","iopub.status.busy":"2022-09-22T09:12:42.390083Z","iopub.status.idle":"2022-09-22T09:12:42.501612Z","shell.execute_reply":"2022-09-22T09:12:42.500571Z","shell.execute_reply.started":"2022-09-22T09:12:42.390732Z"},"trusted":true},"outputs":[],"source":["from torch.nn import Linear\n","from torch_geometric.nn import DynamicEdgeConv\n","from torch_geometric.nn import global_max_pool\n","from torch.nn import Linear as Lin\n","from torch.nn import ReLU\n","from torch.nn import Sequential as Seq\n","\n","num_node_features = 8\n","num_classes = 2\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, c_in, c_hidden, c_out = num_classes, dp_rate_linear=0.3):\n","        super().__init__()\n","        self.dp_rate_linear = dp_rate_linear\n","\n","        nn = Seq(Lin(2*c_in, c_hidden), ReLU(), Lin(c_hidden, c_hidden), ReLU(), Lin(c_hidden, c_hidden), ReLU())\n","        self.conv1 = DynamicEdgeConv(nn, k=20, aggr='max')\n","\n","        nn = Seq(Lin(2*c_hidden, 2*c_hidden), ReLU(), Lin(2*c_hidden, 2*c_hidden), ReLU(), Lin(2*c_hidden, 2*c_hidden),\n","                 ReLU())\n","        self.conv2 = DynamicEdgeConv(nn, k=20, aggr='max')\n","\n","        self.lin1 = Lin(2*c_hidden, c_hidden)\n","        self.lin2 = Lin(c_hidden, c_hidden//2)\n","        self.lin3 = Lin(c_hidden//2, c_out)\n","\n","    def forward(self, x, batch):\n","        x = self.conv1(x, batch)\n","        x = self.conv2(x, batch)\n","\n","        x = global_max_pool(x, batch)\n","\n","        x = F.relu(self.lin1(x))\n","        x = F.relu(self.lin2(x))\n","        x = F.dropout(x, p=self.dp_rate_linear, training=self.training)\n","        x = self.lin3(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Step3: Use PyTorch Lightning to Define Training Process"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:42.503669Z","iopub.status.busy":"2022-09-22T09:12:42.503305Z","iopub.status.idle":"2022-09-22T09:12:42.517122Z","shell.execute_reply":"2022-09-22T09:12:42.515935Z","shell.execute_reply.started":"2022-09-22T09:12:42.503631Z"},"trusted":true},"outputs":[],"source":["from torchmetrics.functional import auroc\n","learning_rate = 3e-4\n","\n","class GraphLevelGNN(pl.LightningModule):\n","    \n","    def __init__(self, **model_kwargs):\n","        super().__init__()\n","        # Saving hyperparameters\n","        self.save_hyperparameters()\n","        \n","        self.model = GCN(**model_kwargs)\n","        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n","        self.auroc = auroc\n","        \n","    def forward(self, data, mode=\"train\"):\n","        x, batch_idx = data.x, data.batch\n","        \n","        x = self.model(x, batch_idx)\n","        x = x.squeeze(dim=-1)\n","        \n","        if self.hparams.c_out == 1:\n","            preds = (x > 0).float()\n","            data.y = data.y.float()\n","        else:\n","            preds = x.argmax(dim=-1)\n","        loss = self.loss_module(x, data.y)\n","        acc = (preds == data.y).sum().float() / preds.shape[0]\n","        auc = self.auroc(x, data.y, num_classes=2)\n","        return loss, acc, auc\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.parameters(), lr=learning_rate, weight_decay=0) # High lr because of small dataset and small model\n","        return optimizer\n","\n","    def training_step(self, batch, batch_idx):\n","        loss, acc, auc = self.forward(batch, mode=\"train\")\n","        self.log('train_loss', loss, prog_bar=True)\n","        self.log('train_acc', acc, prog_bar=True)\n","        self.log('train_auc', auc, prog_bar=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, acc, auc = self.forward(batch, mode=\"val\")\n","        self.log('val_loss', loss, prog_bar=True)\n","        self.log('val_acc', acc, prog_bar=True)\n","        self.log('val_auc', auc, prog_bar=True)\n","\n","    def test_step(self, batch, batch_idx):\n","        loss, acc, auc = self.forward(batch, mode=\"test\")\n","        self.log('test_loss', loss, prog_bar=True)\n","        self.log('test_acc', acc, prog_bar=True)\n","        self.log('test_auc', auc, prog_bar=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:42.519421Z","iopub.status.busy":"2022-09-22T09:12:42.519017Z","iopub.status.idle":"2022-09-22T09:12:42.531933Z","shell.execute_reply":"2022-09-22T09:12:42.530717Z","shell.execute_reply.started":"2022-09-22T09:12:42.519384Z"},"trusted":true},"outputs":[],"source":["CHECKPOINT_PATH = \"./\"\n","def train_graph_classifier(model_name, **model_kwargs):\n","    pl.seed_everything(46)\n","    \n","    # Create a PyTorch Lightning trainer with the generation callback\n","    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n","    os.makedirs(root_dir, exist_ok=True)\n","    trainer = pl.Trainer(default_root_dir=root_dir,\n","                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n","                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n","                         max_epochs=20,\n","                         progress_bar_refresh_rate=5)\n","\n","    # Check whether pretrained model exists. If yes, load it and skip training\n","    model = GraphLevelGNN(**model_kwargs)\n","    print(model)\n","    trainer.fit(model, train_loader, val_loader)\n","    model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n","    \n","    # Test best model on validation and test set\n","    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n","    test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n","    print(val_result)\n","    print(test_result)\n","    result = {\"test\": test_result[0]['test_acc'], \"valid\": val_result[0]['test_acc']} \n","    return model, result"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-22T09:12:42.534116Z","iopub.status.busy":"2022-09-22T09:12:42.533709Z","iopub.status.idle":"2022-09-22T09:20:27.659241Z","shell.execute_reply":"2022-09-22T09:20:27.657900Z","shell.execute_reply.started":"2022-09-22T09:12:42.534079Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=5)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n","  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"]},{"name":"stdout","output_type":"stream","text":["GraphLevelGNN(\n","  (model): GCN(\n","    (conv1): DynamicEdgeConv(nn=Sequential(\n","      (0): Linear(in_features=10, out_features=64, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=64, out_features=64, bias=True)\n","      (3): ReLU()\n","      (4): Linear(in_features=64, out_features=64, bias=True)\n","      (5): ReLU()\n","    ), k=20)\n","    (conv2): DynamicEdgeConv(nn=Sequential(\n","      (0): Linear(in_features=128, out_features=128, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=128, out_features=128, bias=True)\n","      (3): ReLU()\n","      (4): Linear(in_features=128, out_features=128, bias=True)\n","      (5): ReLU()\n","    ), k=20)\n","    (lin1): Linear(in_features=128, out_features=64, bias=True)\n","    (lin2): Linear(in_features=64, out_features=32, bias=True)\n","    (lin3): Linear(in_features=32, out_features=2, bias=True)\n","  )\n","  (loss_module): CrossEntropyLoss()\n",")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:498: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n","  category=PossibleUserWarning,\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35307. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33376. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"109d07ee446a4ce28d3f1c48181a6096","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34507. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35816. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34739. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34756. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36987. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34354. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35833. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34314. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34855. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38323. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35896. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36933. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32082. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33638. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33223. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35418. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33600. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37048. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32437. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 31113. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34982. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34467. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37015. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34025. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38339. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39241. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34542. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33762. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35758. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33026. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35686. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37540. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34419. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36574. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34889. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36649. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36312. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33658. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34457. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35106. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35958. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35461. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32091. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36469. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34288. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35949. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33431. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35854. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37285. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32233. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36373. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35004. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35744. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34465. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32299. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35060. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33670. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34569. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36644. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38699. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35760. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34995. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35665. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 29969. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38178. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37771. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35997. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33154. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34342. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35572. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35513. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34809. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37704. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37501. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 29761. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35743. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35504. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33246. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33853. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38040. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33152. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33470. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36284. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34757. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33292. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35264. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35315. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34184. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 40443. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35721. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36353. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33800. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35779. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33236. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32475. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39997. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36379. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32421. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32830. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38027. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34665. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33465. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35030. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37091. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35503. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32307. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37243. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34774. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36101. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34626. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37038. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 30438. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39240. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35498. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34788. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36319. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 31682. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34877. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35415. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33879. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36875. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37112. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33908. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36094. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36241. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34641. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34914. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38783. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35841. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33046. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35140. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35147. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32408. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32486. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32172. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39379. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33631. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33267. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35746. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36906. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37410. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35164. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34680. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36905. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33184. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39747. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34505. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34729. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33783. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34793. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33835. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33330. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33139. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35254. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34950. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37486. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37657. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 31038. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37109. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36198. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33681. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33016. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35972. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33765. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36623. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33640. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37314. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38265. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33885. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36717. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32631. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33887. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38440. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33494. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33706. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37444. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35049. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:498: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n","  category=PossibleUserWarning,\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e596443f7b084ff9be151a005a500191","version_major":2,"version_minor":0},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34319. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34818. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36228. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33381. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37609. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36934. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34749. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad05c9453ebc40c09bf5e99c68a0d374","version_major":2,"version_minor":0},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36159. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37188. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36452. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37869. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38872. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37743. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37301. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34396. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"name":"stdout","output_type":"stream","text":["[{'test_loss': 0.3713477551937103, 'test_acc': 0.818640947341919, 'test_auc': 0.8673312664031982}]\n","[{'test_loss': 0.403104692697525, 'test_acc': 0.8088625073432922, 'test_auc': 0.8626824021339417}]\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34276. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]}],"source":["import os\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model, result = train_graph_classifier(model_name=\"GCN\", c_in=5, c_hidden=64, c_out=2)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 64-bit (system)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"d507929f44837d1daaf29f29c4c1ca0d68fa87396bd59872bf4a0b653e2f30d1"}}},"nbformat":4,"nbformat_minor":4}
