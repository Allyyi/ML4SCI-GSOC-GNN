{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-21T07:57:18.825194Z","iopub.status.busy":"2022-09-21T07:57:18.824503Z","iopub.status.idle":"2022-09-21T07:59:32.107601Z","shell.execute_reply":"2022-09-21T07:59:32.106401Z","shell.execute_reply.started":"2022-09-21T07:57:18.825089Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n","Collecting torch==1.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (1637.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m714.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:02\u001b[0m\n","\u001b[?25hCollecting torchvision==0.12.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (22.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchaudio==0.11.0 in /opt/conda/lib/python3.7/site-packages (0.11.0)\n","Collecting torchaudio==0.11.0\n","  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0+cu113) (4.1.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0+cu113) (2.28.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0+cu113) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0+cu113) (9.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0+cu113) (2022.6.15)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0+cu113) (1.26.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0+cu113) (3.3)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0+cu113) (2.1.0)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0\n","    Uninstalling torch-1.11.0:\n","      Successfully uninstalled torch-1.11.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.12.0\n","    Uninstalling torchvision-0.12.0:\n","      Successfully uninstalled torchvision-0.12.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.11.0\n","    Uninstalling torchaudio-0.11.0:\n","      Successfully uninstalled torchaudio-0.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install --upgrade torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n","!python -c \"import torch; print(torch.__version__); print(torch.version.cuda);\"\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu113.html"]},{"cell_type":"markdown","metadata":{},"source":["## Step1: Data Preprocessing\n","Detailed explaination can be found in data_exploration.ipynb"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T07:59:51.079923Z","iopub.status.busy":"2022-09-21T07:59:51.079000Z","iopub.status.idle":"2022-09-21T07:59:54.727851Z","shell.execute_reply":"2022-09-21T07:59:54.726776Z","shell.execute_reply.started":"2022-09-21T07:59:51.079880Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import gc\n","import torch\n","import pyarrow as pa\n","from tqdm import tqdm\n","from pyarrow.parquet import ParquetFile\n","from sklearn.neighbors import kneighbors_graph\n","from sklearn.model_selection import train_test_split\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T07:59:54.730291Z","iopub.status.busy":"2022-09-21T07:59:54.729562Z","iopub.status.idle":"2022-09-21T08:00:43.228154Z","shell.execute_reply":"2022-09-21T08:00:43.227006Z","shell.execute_reply.started":"2022-09-21T07:59:54.730236Z"},"trusted":true},"outputs":[],"source":["import glob\n","import pandas as pd\n","ds_dir = glob.glob('../input/boosted-top-tau-4/*')\n","X_jets = []\n","lables = []\n","\n","for file_name in ds_dir:\n","    df = pd.read_parquet(file_name)\n","    X_jets.append(np.array(df['X_jets'].tolist()).astype(np.float32))\n","    lables.append(df['y'].to_numpy())\n","    del df"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:00:43.229910Z","iopub.status.busy":"2022-09-21T08:00:43.229531Z","iopub.status.idle":"2022-09-21T08:00:45.860865Z","shell.execute_reply":"2022-09-21T08:00:45.859729Z","shell.execute_reply.started":"2022-09-21T08:00:43.229866Z"},"trusted":true},"outputs":[],"source":["X_jets = np.array(X_jets).reshape((-1,125000))\n","lables = np.array(lables).reshape((-1,1))\n","X_data = X_jets.reshape((-1,125*125,8))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:00:45.875420Z","iopub.status.busy":"2022-09-21T08:00:45.874715Z","iopub.status.idle":"2022-09-21T08:00:52.408188Z","shell.execute_reply":"2022-09-21T08:00:52.407136Z","shell.execute_reply.started":"2022-09-21T08:00:45.875382Z"},"trusted":true},"outputs":[],"source":["# uncommet this line below if choose to use full channels for node features\n","X_data = X_data[:,:,:5]\n","non_black_pixels_mask = np.any(X_data != 0., axis=-1)\n","\n","node_list = []\n","for i, x in enumerate(X_data):\n","    node_list.append(x[non_black_pixels_mask[i]])\n","\n","# clear cache after use due to RAM limits\n","del X_jets, X_data, non_black_pixels_mask"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:00:52.410322Z","iopub.status.busy":"2022-09-21T08:00:52.409901Z","iopub.status.idle":"2022-09-21T08:02:13.720497Z","shell.execute_reply":"2022-09-21T08:02:13.718942Z","shell.execute_reply.started":"2022-09-21T08:00:52.410284Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 9600/9600 [01:21<00:00, 118.09it/s]\n"]}],"source":["dataset = []\n","for i,nodes in enumerate(tqdm(node_list)):\n","    edges = kneighbors_graph(nodes, 15, mode='connectivity', include_self=True)\n","    c = edges.tocoo()\n","    edge_list = torch.from_numpy(np.vstack((c.row, c.col))).type(torch.long)\n","    edge_weight = torch.from_numpy(c.data.reshape(-1,1))\n","    y = lables[i]\n","    dataset.append(Data(x=torch.from_numpy(nodes), edge_index=edge_list, edge_attr=edge_weight, y=torch.from_numpy(y).long()))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:02:13.723015Z","iopub.status.busy":"2022-09-21T08:02:13.722289Z","iopub.status.idle":"2022-09-21T08:02:13.906258Z","shell.execute_reply":"2022-09-21T08:02:13.905121Z","shell.execute_reply.started":"2022-09-21T08:02:13.722975Z"},"trusted":true},"outputs":[{"data":{"text/plain":["551"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["del lables, node_list, edge_list, edge_weight, y\n","gc.collect()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:02:13.920014Z","iopub.status.busy":"2022-09-21T08:02:13.919640Z","iopub.status.idle":"2022-09-21T08:02:13.940744Z","shell.execute_reply":"2022-09-21T08:02:13.939527Z","shell.execute_reply.started":"2022-09-21T08:02:13.919977Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["7776 864 864\n"]}],"source":["rand_seed = 42\n","X_train, X_test = train_test_split(dataset, test_size=0.1, random_state = rand_seed)\n","X_train, X_val = train_test_split(X_train, test_size=0.1, random_state = rand_seed)\n","print(len(X_train), len(X_val), len(X_val))"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:02:13.946011Z","iopub.status.busy":"2022-09-21T08:02:13.945712Z","iopub.status.idle":"2022-09-21T08:02:14.018118Z","shell.execute_reply":"2022-09-21T08:02:14.016543Z","shell.execute_reply.started":"2022-09-21T08:02:13.945986Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch: DataBatch(x=[43043, 5], edge_index=[2, 645645], edge_attr=[645645, 1], y=[32], batch=[43043], ptr=[33])\n","Labels: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 1])\n","Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"]}],"source":["train_loader = DataLoader(X_train, batch_size=32, shuffle=True)\n","val_loader = DataLoader(X_val, batch_size=32, shuffle=False)\n","test_loader = DataLoader(X_test, batch_size=32, shuffle=False)\n","batch = next(iter(test_loader))\n","print(\"Batch:\", batch)\n","print(\"Labels:\", batch.y[:10])\n","print(\"Batch indices:\", batch.batch[:40])"]},{"cell_type":"markdown","metadata":{},"source":["## Step2: Define Graph SAGE Model"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:02:14.019680Z","iopub.status.busy":"2022-09-21T08:02:14.019342Z","iopub.status.idle":"2022-09-21T08:02:14.025399Z","shell.execute_reply":"2022-09-21T08:02:14.024416Z","shell.execute_reply.started":"2022-09-21T08:02:14.019644Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torch.optim as optim\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:02:14.027555Z","iopub.status.busy":"2022-09-21T08:02:14.026640Z","iopub.status.idle":"2022-09-21T08:02:14.292094Z","shell.execute_reply":"2022-09-21T08:02:14.291197Z","shell.execute_reply.started":"2022-09-21T08:02:14.027421Z"},"trusted":true},"outputs":[],"source":["from torch.nn import Linear\n","from torch_geometric.nn import SAGEConv, TopKPooling\n","from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n","num_node_features = 5\n","num_classes = 2\n","class GCN(torch.nn.Module):\n","    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.3):\n","        super().__init__()\n","        torch.manual_seed(123)\n","        \n","        self.conv1 = SAGEConv(c_in, c_hidden)\n","        self.pool1 = TopKPooling(c_hidden, ratio=0.8)\n","        self.conv2 = SAGEConv(c_hidden, c_hidden)\n","        self.pool2 = TopKPooling(c_hidden, ratio=0.8)\n","        self.conv3 = SAGEConv(c_hidden, c_hidden)\n","        self.pool3 = TopKPooling(c_hidden, ratio=0.8)\n","        self.lin1 = torch.nn.Linear(c_hidden*2, c_hidden)\n","        self.lin2 = torch.nn.Linear(c_hidden, c_out)\n","        self.act1 = torch.nn.ReLU()\n","        self.act2 = torch.nn.ReLU()\n","        self.dp_rate_linear = dp_rate_linear\n","  \n","    def forward(self, x, edge_index, batch):       \n","        x = F.relu(self.conv1(x, edge_index))\n","        #x, edge_index, edge_attr, batch, perm, score[perm]\n","\n","        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n","        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n","\n","        x = F.relu(self.conv2(x, edge_index))\n","     \n","        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n","        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n","\n","        x = F.relu(self.conv3(x, edge_index))\n","\n","        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n","        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n","\n","        x = x1 + x2 + x3\n","\n","        x = self.lin1(x)\n","        x = self.act1(x)\n","        x = self.lin2(x)\n","        x = self.act2(x)      \n","        x = F.dropout(x, p=self.dp_rate_linear, training=self.training)\n","\n","        return x "]},{"cell_type":"markdown","metadata":{},"source":["## Step3: Use PyTorch Lightning to Define Training Process"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:02:14.294016Z","iopub.status.busy":"2022-09-21T08:02:14.293650Z","iopub.status.idle":"2022-09-21T08:02:14.308240Z","shell.execute_reply":"2022-09-21T08:02:14.306782Z","shell.execute_reply.started":"2022-09-21T08:02:14.293981Z"},"trusted":true},"outputs":[],"source":["from torchmetrics.functional import auroc\n","class GraphLevelGNN(pl.LightningModule):\n","    \n","    def __init__(self, **model_kwargs):\n","        super().__init__()\n","        # Saving hyperparameters\n","        self.save_hyperparameters()\n","        \n","        self.model = GCN(**model_kwargs)\n","        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n","        self.auroc = auroc\n","        \n","    def forward(self, data, mode=\"train\"):\n","        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n","        # print(data.x.shape, data.edge_index.shape, data.batch.shape)\n","        \n","        x = self.model(x, edge_index, batch_idx)\n","        x = x.squeeze(dim=-1)\n","        \n","        if self.hparams.c_out == 1:\n","            preds = (x > 0).float()\n","            data.y = data.y.float()\n","        else:\n","            preds = x.argmax(dim=-1)\n","        loss = self.loss_module(x, data.y)\n","        acc = (preds == data.y).sum().float() / preds.shape[0]\n","        auc = self.auroc(x, data.y, num_classes=2)\n","        return loss, acc, auc\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.parameters(), lr=3e-4, weight_decay=0) # High lr because of small dataset and small model\n","        return optimizer\n","\n","    def training_step(self, batch, batch_idx):\n","        loss, acc, auc = self.forward(batch, mode=\"train\")\n","        self.log('train_loss', loss, prog_bar=True)\n","        self.log('train_acc', acc, prog_bar=True)\n","        self.log('train_auc', auc, prog_bar=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, acc, auc = self.forward(batch, mode=\"val\")\n","        self.log('val_loss', loss, prog_bar=True)\n","        self.log('val_acc', acc, prog_bar=True)\n","        self.log('val_auc', auc, prog_bar=True)\n","\n","    def test_step(self, batch, batch_idx):\n","        loss, acc, auc = self.forward(batch, mode=\"test\")\n","        self.log('test_loss', loss, prog_bar=True)\n","        self.log('test_acc', acc, prog_bar=True)\n","        self.log('test_auc', auc, prog_bar=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:02:14.310403Z","iopub.status.busy":"2022-09-21T08:02:14.309956Z","iopub.status.idle":"2022-09-21T08:02:14.324709Z","shell.execute_reply":"2022-09-21T08:02:14.323699Z","shell.execute_reply.started":"2022-09-21T08:02:14.310367Z"},"trusted":true},"outputs":[],"source":["CHECKPOINT_PATH = \"./\"\n","def train_graph_classifier(model_name, **model_kwargs):\n","    pl.seed_everything(42)\n","    \n","    # Create a PyTorch Lightning trainer with the generation callback\n","    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n","    os.makedirs(root_dir, exist_ok=True)\n","    trainer = pl.Trainer(default_root_dir=root_dir,\n","                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n","                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n","                         max_epochs=20,\n","                         progress_bar_refresh_rate=5)\n","\n","    # Check whether pretrained model exists. If yes, load it and skip training\n","    model = GraphLevelGNN(**model_kwargs)\n","    print(model)\n","    trainer.fit(model, train_loader, val_loader)\n","    model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n","    \n","    # Test best model on validation and test set\n","    # train_result = trainer.test(model, dataloaders=train_loader, verbose=False)\n","    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n","    test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n","    result = {\"test\": test_result[0]['test_acc'], \"valid\": val_result[0]['test_acc']} \n","    print(val_result)\n","    print(test_result)\n","    return model, result"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-09-21T08:02:14.327946Z","iopub.status.busy":"2022-09-21T08:02:14.327690Z","iopub.status.idle":"2022-09-21T08:06:56.427847Z","shell.execute_reply":"2022-09-21T08:06:56.426818Z","shell.execute_reply.started":"2022-09-21T08:02:14.327922Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=5)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n","  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"]},{"name":"stdout","output_type":"stream","text":["GraphLevelGNN(\n","  (model): GCN(\n","    (conv1): SAGEConv(5, 64, aggr=mean)\n","    (pool1): TopKPooling(64, ratio=0.8, multiplier=1.0)\n","    (conv2): SAGEConv(64, 64, aggr=mean)\n","    (pool2): TopKPooling(64, ratio=0.8, multiplier=1.0)\n","    (conv3): SAGEConv(64, 64, aggr=mean)\n","    (pool3): TopKPooling(64, ratio=0.8, multiplier=1.0)\n","    (lin1): Linear(in_features=128, out_features=64, bias=True)\n","    (lin2): Linear(in_features=64, out_features=2, bias=True)\n","    (act1): ReLU()\n","    (act2): ReLU()\n","  )\n","  (loss_module): CrossEntropyLoss()\n",")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37375. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37001. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"149e36fc06bd475b90f951672c0294f7","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33933. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34128. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 40583. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38353. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37492. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38219. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 30998. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37288. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38142. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37033. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37136. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38660. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35531. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34457. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33169. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34554. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37247. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 44394. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38064. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35701. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36002. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34431. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39771. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 40110. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35100. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22e691e701404a24a1a4c6528f7a215c","version_major":2,"version_minor":0},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"975aede6543f4d4d87e933cb74f9f24a","version_major":2,"version_minor":0},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 43043. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38576. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 41724. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36159. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37095. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34138. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36240. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38741. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34506. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36890. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37904. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37209. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34270. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 40406. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32965. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35933. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37531. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36499. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35859. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36082. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32161. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38393. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38996. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37045. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 40323. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 40541. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36225. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34118. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"name":"stdout","output_type":"stream","text":["[{'test_loss': 0.41307148337364197, 'test_acc': 0.8281190991401672, 'test_auc': 0.8758936524391174}]\n","[{'test_loss': 0.416495144367218, 'test_acc': 0.814951479434967, 'test_auc': 0.8623855113983154}]\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34894. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37376. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]}],"source":["import os\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model, result = train_graph_classifier(model_name=\"GCN\", c_in=5, c_hidden=64, c_out=2)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 64-bit (system)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"d507929f44837d1daaf29f29c4c1ca0d68fa87396bd59872bf4a0b653e2f30d1"}}},"nbformat":4,"nbformat_minor":4}
