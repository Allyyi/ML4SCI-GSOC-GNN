{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n!python -c \"import torch; print(torch.__version__); print(torch.version.cuda);\"\n!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu113.html","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step1: Dataset Preprocessing","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport gc\nimport torch\nimport pyarrow as pa\nfrom tqdm import tqdm\nfrom pyarrow.parquet import ParquetFile\nfrom sklearn.neighbors import kneighbors_graph\nfrom sklearn.model_selection import train_test_split\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:23:23.663745Z","iopub.execute_input":"2022-09-30T09:23:23.664155Z","iopub.status.idle":"2022-09-30T09:23:27.903974Z","shell.execute_reply.started":"2022-09-30T09:23:23.664122Z","shell.execute_reply":"2022-09-30T09:23:27.902804Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import glob\nimport pandas as pd\ntau_dataset = glob.glob('../input/boosted-top-tau-4/*')\nX_jets = []\nlables = []\n\nfor file_name in tau_dataset:\n    df = pd.read_parquet(file_name)\n    X_jets.append(np.array(df['X_jets'].tolist()).astype(np.float32))\n    lables.append(df['y'].to_numpy())\n    del df","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:23:27.906272Z","iopub.execute_input":"2022-09-30T09:23:27.908506Z","iopub.status.idle":"2022-09-30T09:24:16.549171Z","shell.execute_reply.started":"2022-09-30T09:23:27.908466Z","shell.execute_reply":"2022-09-30T09:24:16.547903Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_jets = np.array(X_jets).reshape((-1,125000))\nlables = np.array(lables).reshape((-1,1))","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:24:16.550851Z","iopub.execute_input":"2022-09-30T09:24:16.551241Z","iopub.status.idle":"2022-09-30T09:24:18.694695Z","shell.execute_reply.started":"2022-09-30T09:24:16.551202Z","shell.execute_reply":"2022-09-30T09:24:18.693584Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_data = X_jets.reshape((-1,125*125,8))\nX_data = X_data[:,:,:5]\nnon_black_pixels_mask = np.any(X_data != 0., axis=-1)\n\nnode_list = []\nfor i, x in enumerate(X_data):\n    node_list.append(x[non_black_pixels_mask[i]])\ndel X_jets, X_data, non_black_pixels_mask\n","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:24:18.697197Z","iopub.execute_input":"2022-09-30T09:24:18.697909Z","iopub.status.idle":"2022-09-30T09:24:25.524694Z","shell.execute_reply.started":"2022-09-30T09:24:18.697867Z","shell.execute_reply":"2022-09-30T09:24:25.523636Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset = []\nfor i,nodes in enumerate(tqdm(node_list)):\n    edges = kneighbors_graph(nodes, 15, mode='connectivity', include_self=True)\n    c = edges.tocoo()\n    edge_list = torch.from_numpy(np.vstack((c.row, c.col))).type(torch.long)\n    edge_weight = torch.from_numpy(c.data.reshape(-1,1))\n    y = lables[i]\n    dataset.append(Data(x=torch.from_numpy(nodes), edge_index=edge_list, edge_attr=edge_weight, y=torch.from_numpy(y).long()))","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:24:25.526211Z","iopub.execute_input":"2022-09-30T09:24:25.527249Z","iopub.status.idle":"2022-09-30T09:25:47.598939Z","shell.execute_reply.started":"2022-09-30T09:24:25.527205Z","shell.execute_reply":"2022-09-30T09:25:47.597897Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 9600/9600 [01:22<00:00, 116.99it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"del lables, node_list, edge_list, edge_weight, y\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:25:47.600373Z","iopub.execute_input":"2022-09-30T09:25:47.601238Z","iopub.status.idle":"2022-09-30T09:25:47.793821Z","shell.execute_reply.started":"2022-09-30T09:25:47.601198Z","shell.execute_reply":"2022-09-30T09:25:47.792645Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"911"},"metadata":{}}]},{"cell_type":"code","source":"rand_seed = 42\nX_train, X_test = train_test_split(dataset, test_size=0.1, random_state = rand_seed)\nX_train, X_val = train_test_split(X_train, test_size=0.1, random_state = rand_seed)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:26:16.760687Z","iopub.execute_input":"2022-09-30T09:26:16.761132Z","iopub.status.idle":"2022-09-30T09:26:16.775527Z","shell.execute_reply.started":"2022-09-30T09:26:16.761097Z","shell.execute_reply":"2022-09-30T09:26:16.774454Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(X_train, batch_size=32, shuffle=True)\nval_loader = DataLoader(X_val, batch_size=32, shuffle=False)\ntest_loader = DataLoader(X_test, batch_size=32, shuffle=False)\n\nbatch = next(iter(test_loader))\nprint(\"Batch:\", batch)\nprint(\"Labels:\", batch.y[:10])\nprint(\"Batch indices:\", batch.batch[:40])","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:26:18.331403Z","iopub.execute_input":"2022-09-30T09:26:18.331784Z","iopub.status.idle":"2022-09-30T09:26:18.398401Z","shell.execute_reply.started":"2022-09-30T09:26:18.331751Z","shell.execute_reply":"2022-09-30T09:26:18.397286Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Batch: DataBatch(x=[37894, 5], edge_index=[2, 568410], edge_attr=[568410, 1], y=[32], batch=[37894], ptr=[33])\nLabels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\nBatch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step2: Define Graph Convolution GNN Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.optim as optim\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:26:22.978927Z","iopub.execute_input":"2022-09-30T09:26:22.979300Z","iopub.status.idle":"2022-09-30T09:26:22.985459Z","shell.execute_reply.started":"2022-09-30T09:26:22.979270Z","shell.execute_reply":"2022-09-30T09:26:22.983805Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from torch.nn import Linear\nfrom torch_geometric.nn import GraphConv\nfrom torch_geometric.nn import global_mean_pool\n\nnum_node_features = 5\nnum_classes = 2\n\nclass GCN(torch.nn.Module):\n    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.3):\n        super().__init__()\n        torch.manual_seed(123)\n        self.conv1 = GraphConv(c_in, c_hidden)\n        self.conv2 = GraphConv(c_hidden,2*c_hidden)\n        self.conv3 = GraphConv(2*c_hidden, c_hidden)\n        self.lin1 = Linear(c_hidden, 4*c_out)\n        self.lin2 = Linear(4*c_out, c_out)\n        self.dp_rate_linear = dp_rate_linear\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = self.conv2(x, edge_index)\n        x = x.relu()\n        x = self.conv3(x, edge_index)\n\n        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n\n        # classifier\n        x = F.dropout(x, p=self.dp_rate_linear, training=self.training)\n        x = self.lin1(x)\n        x = F.dropout(x, p=self.dp_rate_linear, training=self.training)\n        x = self.lin2(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:26:25.951365Z","iopub.execute_input":"2022-09-30T09:26:25.951764Z","iopub.status.idle":"2022-09-30T09:26:26.128565Z","shell.execute_reply.started":"2022-09-30T09:26:25.951731Z","shell.execute_reply":"2022-09-30T09:26:26.127609Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Step3: Use PyTorch Lightning to Define Training Process","metadata":{}},{"cell_type":"code","source":"from torchmetrics.functional import auroc\nclass GraphLevelGNN(pl.LightningModule):\n    \n    def __init__(self, **model_kwargs):\n        super().__init__()\n        # Saving hyperparameters\n        self.save_hyperparameters()\n        \n        self.model = GCN(**model_kwargs)\n        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n        self.auroc = auroc\n        \n    def forward(self, data, mode=\"train\"):\n        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n        # print(data.x.shape, data.edge_index.shape, data.batch.shape)\n        \n        x = self.model(x, edge_index, batch_idx)\n        x = x.squeeze(dim=-1)\n        \n        if self.hparams.c_out == 1:\n            preds = (x > 0).float()\n            data.y = data.y.float()\n        else:\n            preds = x.argmax(dim=-1)\n        loss = self.loss_module(x, data.y)\n        acc = (preds == data.y).sum().float() / preds.shape[0]\n        auc = self.auroc(x, data.y, num_classes=2)\n        return loss, acc, auc\n\n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=3e-4, weight_decay=0) # High lr because of small dataset and small model\n        return optimizer\n\n    def training_step(self, batch, batch_idx):\n        loss, acc, auc = self.forward(batch, mode=\"train\")\n        self.log('train_loss', loss, prog_bar=True)\n        self.log('train_acc', acc, prog_bar=True)\n        self.log('train_auc', auc, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, acc, auc = self.forward(batch, mode=\"val\")\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True)\n        self.log('val_auc', auc, prog_bar=True)\n\n    def test_step(self, batch, batch_idx):\n        loss, acc, auc = self.forward(batch, mode=\"test\")\n        self.log('test_loss', loss, prog_bar=True)\n        self.log('test_acc', acc, prog_bar=True)\n        self.log('test_auc', auc, prog_bar=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:29:43.041489Z","iopub.execute_input":"2022-09-30T09:29:43.042142Z","iopub.status.idle":"2022-09-30T09:29:43.072159Z","shell.execute_reply.started":"2022-09-30T09:29:43.042099Z","shell.execute_reply":"2022-09-30T09:29:43.070598Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"CHECKPOINT_PATH = \"./\"\ndef train_graph_classifier(model_name, **model_kwargs):\n    pl.seed_everything(42)\n    \n    # Create a PyTorch Lightning trainer with the generation callback\n    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n    os.makedirs(root_dir, exist_ok=True)\n    trainer = pl.Trainer(default_root_dir=root_dir,\n                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n                         max_epochs=20,\n                         progress_bar_refresh_rate=5)\n\n    # Check whether pretrained model exists. If yes, load it and skip training\n    model = GraphLevelGNN(**model_kwargs)\n    print(model)\n    trainer.fit(model, train_loader, val_loader)\n    model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n    \n    # Test best model on validation and test set\n    # train_result = trainer.test(model, dataloaders=train_loader, verbose=False)\n    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n    test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n    print(val_result, test_result)\n    result = {\"test\": test_result[0]['test_acc'], \"valid\": val_result[0]['test_acc']} \n    return model, result","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:33:11.662359Z","iopub.execute_input":"2022-09-30T09:33:11.662780Z","iopub.status.idle":"2022-09-30T09:33:11.671806Z","shell.execute_reply.started":"2022-09-30T09:33:11.662746Z","shell.execute_reply":"2022-09-30T09:33:11.670681Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import os\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel, result = train_graph_classifier(model_name=\"GCN\", c_in=5, c_hidden=64, c_out=2)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T09:33:15.663440Z","iopub.execute_input":"2022-09-30T09:33:15.663828Z","iopub.status.idle":"2022-09-30T09:36:11.905494Z","shell.execute_reply.started":"2022-09-30T09:33:15.663794Z","shell.execute_reply":"2022-09-30T09:36:11.904432Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"GraphLevelGNN(\n  (model): GCN(\n    (conv1): GraphConv(5, 64)\n    (conv2): GraphConv(64, 128)\n    (conv3): GraphConv(128, 64)\n    (lin1): Linear(in_features=64, out_features=8, bias=True)\n    (lin2): Linear(in_features=8, out_features=2, bias=True)\n  )\n  (loss_module): CrossEntropyLoss()\n)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"648b9dbf91aa4c529f118db98f4e7dcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b1a5843717146c8ab7990fd06f43eb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"566fe0caf1724bd5af948d49b773bda3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37894. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36070. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37946. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34139. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34834. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34849. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34120. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 40075. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35529. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38000. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36891. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 37018. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33240. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 33340. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32783. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32416. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36627. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36061. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34600. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36257. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34768. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36569. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36760. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35839. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38141. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35855. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36117. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 29400. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34906. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:73: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 36252. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","output_type":"stream"},{"name":"stdout","text":"[{'test_loss': 0.40515729784965515, 'test_acc': 0.8140714764595032, 'test_auc': 0.85390305519104}] [{'test_loss': 0.375895231962204, 'test_acc': 0.8309985399246216, 'test_auc': 0.8593456149101257}]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}